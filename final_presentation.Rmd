---
title: "Right contex effects and adaptation of stop consonants (in English)"
subtitle: ""
author: "Joselyn Rodriguez"
institute: "Rutgers University"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, rutgers, rutgers-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

<!-- 

#### TODO 


1. Relevel variables.
  - the base factor should be /t/-biasing
  - make sure VOT is centered correctly
  
2. Calculate Rope

3. Plot posterior estimates

4. Actually set your priors

-->


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(tidyverse)
library(rstanarm)
library(brms)
library(tidybayes)
library(lme4)
library(lmerTest)
library(psych)
library(bayesplot)
library(ProbBayes)
```


```{r load-data}

# load some data that i'll need real quick

temp <- read_csv("data/batch1-test.csv") 

# releveld w/pre:tent-biasing as the intercept
test <- temp %>% 
      mutate(block = factor(block, levels=c("pre", "post")),
             resp_t = as.numeric(resp_t))  %>%
      mutate(condition = factor(condition, levels = c("tent-biasing", "dent-biasing"))) %>% 
      mutate(vot = (vot - mean(vot))) # centering

test %>% 
  group_by(workerId) %>% 
  summarize(average = mean(resp_t), sd = sd(resp_t))

pre_test <- test %>% 
  filter(block == "pre")
nrow(pre_test)

post_test <- test %>% 
  filter(block == "post")
nrow(post_test)

# I'm not gonna use this data for the class i dont think
# exposure <- read_csv("data/batch1-exposure.csv")
```


# Jumping right in: The study
 
- Given previous research finding that when an ambiguous segment is encountered, listeners do not immediately try to disambiguate it to determine a lexical item, but maintain uncertainty until disambiguating information is encountered, we were interested in 
  - (1) what information is available 
  - (2) whether this finer-grained information is available for updating/learning
--

- Moving on...

---

# Jumping right in: The study

- In order to test whether or not this semantic information that is available after encountering an ambiguous item is available to use in updating of representational information, we used a **perceptual learning** paradigm.
  - Norris et al. (2003), Eisner & McQueen (2005), 

--

### Perceptual learning paradigms: the gist


Pre-test --> Recalibration of some sort --> Post-test (yay! learning hopefully)

<!-- insert pic of the process -->

---

# Methods 

- for this study, the methods were similar to other perceptual learning paradigms but instead of having a recalibration take place through lexical disambiguation, we used semantic disambiguation. 

- ex:

"After the tent in the | campgrounds collapsed, we went to a hotel."


- the critical sentences were taken from a previous study examining semantic right context effects on sentence comprehension and were re-recorded by one female speaker of American English (not me)
  - Connine et al. (1991)
---

# Methods
#### Pre-test

- stimuli for the pre-test consisted of a VOT continuum ranging from 15-85ms at 5ms intervals and were presented as "the tent" and "the dent" with only the VOT of the /t/ and /d/ differing between the two
- this lasted about 11 minutes 
--

#### Exposure 
- sentences mentioned above. Each were "short lag" sentences such that the disambiguating information was provided within 3-5 syllables of encountering the ambiguous word
- participants were asked to respond whether they heard "tent" or "dent" used in the sentence
  - this was both as an attention check as well as a way of comparing these findings to previous studies
    - i.e., Connine et al (1991)
--

#### Pos-test
- identical to the pre-test

---

# Visualize then Analyze
## First, let's take a look at our raw data to get an idea of what it looks like 

```{r glimpse-data}
head(test, n=10)
```


```{r visualize}

ggplot(data = test,
       aes(x=vot, y=resp_t, color = condition)) +
  # uncomment to see the actual data points instead of just the mean
  geom_point(position=position_jitter(h = 0.05), alpha=0.1) +
  geom_line(stat="summary", fun = mean) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  facet_wrap( . ~ block) +
  ylab("Proportion of /t/ response") + xlab("VOT (ms)") +
  labs(title = "*Pre- and Post Continuum 'Tent' Responses*", tag = "Figure 1") +
  mdthemes::md_theme_bw() +
  theme(text=element_text(size=11, family = "Times"))

```


---
# Analysis (the important part)
## Bayesian vs. Frequentist analysis of the pre/post-test data

- utilized a Bayesian multi-level model (using brms) and a Frequentist model using (lme4)

- we are utilizing a multi-level logistic regression because...
  - the data is looking at the proportion of /t/-responses (for pre/post tests)
  - and accuracy along with proportion /t/-responses (for exposure)
- multi-level because...
  - we're interested in group-level effects since it's repeated measures and because we want to look at within-participant effects
  
---
# Analysis
## Bayesian vs. Frequentist analysis of the pre/post-test data

.Large[$$\hat{y} = \alpha + {\beta}{X} + {u}{Z} + \epsilon $$]

- recall the equation for MLM


---
# Analysis
## Test data

- Frequentist approach: 

- in order to compare the pre- and post-test, I used lme4 to run the following model: 
  - `glmer(resp_t ~ block * condition * vot + (block | workerId) + (1 | stimulus), data = test, family = "binomial"(link = "logit")`
  
  - taking this apart:
    - glmer: a generali**zed** multi-level regression model 
    - outcome variable: proportion of /t/ responses
    - fixed effects: block (pre vs. post), condition (tent or dent-biasing), and vot
    - random effects: workerId, item, block
      - specifically, random intercepts by item and subject and by subject random slopes for blocks

```{r frequentist, eval=FALSE, include=FALSE}
# convert to probability: logit2prob <- function(logit){
#   odds <- exp(logit)
#   prob <- odds / (1 + odds)
#   return(prob)
# }
# infinite thanks to: https://sebastiansauer.github.io/convert_logit2prob/

# you could add a random intercept for condition, but it may or may not add any real explanatory value. that would technically contribute to like "maximal" random effects structure though

#### Begin Frequentist Modeling

# intercept model 
freq_analysis_int <- glm(resp_t ~ 1, data = test, family = "binomial"(link = "logit"))
summary(freq_analysis_int)

# including interaction and one random effect
freq_analysis_1 <- glmer(resp_t ~ block * condition * vot +
                                  (1 | workerId),
                                  data = test, family = "binomial"(link = "logit"))
# adding one more random effect
freq_analysis_2 <- glmer(resp_t ~ block * condition * vot +
                                  (1 | workerId) +
                                  (1 | stimulus),
                                  data = test, family = "binomial"(link = "logit"), 
                                  control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5)))

#### Model comparison
freq_anova <-  anova(freq_analysis_1, freq_analysis_2 , freq_analysis_full, test = "Chisq") # well it looks like including stimulus is better?

```

---

# Analysis
## Test data

- Let's take a look at the output
  - things to consider:
      - the vot was centered around the mean
      - the intercept is pre-test and "tent"-biasing
  - significant effects:
    - interaction (yay)
    - vot (expected)
    - intercept (mean: (prob) 0.7267025)
      - the probability of /t/ response in the pre-test and tent-biasing condition given a vot of 50 (remember it's centered around 0 here)
      - which isn't great because around the center should be ambiguous but that's a problem for future me

```{r frequentist-summary}
# adding in a random slope and lets goooo
freq_analysis_full <- glmer(resp_t ~ block * condition * vot +
                                  (block | workerId) +
                                  (1 | stimulus),
                                  data = test, family = "binomial"(link = "logit"), 
                                  control=glmerControl(optimizer="bobyqa",
                                  optCtrl=list(maxfun=2e5)))
# Let's take a look at the summary for the full model 
freq_summary <- summary(freq_analysis_full)
```


---
# Analysis
# test data

- Bayesian approach: 

- alright, this is very similar, but we're going to make a few adjustments. 
  - `brm(resp_t ~ block * condition * vot + (block | workerId) + (1 | stimulus), data = test, family = "bernoulli"(link = "logit")`
  
```{r bayesian, eval=FALSE, include=FALSE}
#### Bayesian Modeling 

# intercept model
bayes_analysis_int <- brm(resp_t ~ 1, data = test, family = "bernoulli"(link = "logit"))
summary(bayes_analysis_int)

# adding in one random intercept
bayes_analysis_1 <- brm(resp_t ~ block * condition * vot +
                                  (1 | workerId),
                                  data = test, family = "bernoulli"(link = "logit"))
summary(bayes_analysis_1)

# adding in another random intercept
bayes_analysis_2 <- brm(resp_t ~ block * condition * vot +
                                  (1 | workerId) +
                                  (1 | stimulus),
                                  data = test, family = "bernoulli"(link = "logit"),
                                  prior = c(prior("normal(0,0.5)", class = "b"), # setting priors (remember -4 to 4)
                                            prior("normal(0,1", class = "Intercept")),
                                  cores = getOption("mc.cores", 4),
                                  save_pars = save_pars(all = T))
summary(bayes_analysis_2)

```

```{r bayesian-summary}
# finally, random intercepts and random slope for block
bayes_analysis_full <- brm(resp_t ~ block * condition * vot +
                                  (block | workerId) +
                                  (1 | stimulus),
                                  data = test, family = "bernoulli"(link = "logit"), 
                                  prior = c(prior("normal(0,0.5)", class = "b"), # setting priors (remember -4 to 4)
                                            prior("normal(0,1", class = "Intercept")), # setting priors (remember -4 to 4)
                                  cores = getOption("mc.cores", 4),
                                  save_pars = save_pars(all = T))
bayes_summary <- summary(bayes_analysis_full)
bayes_summary
```


---
# Analysis
# test data

- let's take a closer look at our posterior estimates

```{r parameter-estimates}
# ROPE calculated as: [-0.18, 0.18]
posterior_table <- as_tibble(bayes_analysis_full)

p1 <- posterior_table %>% 
  select(c("b_Intercept":"b_blockpost:conditiondentMbiasing:vot")) %>% 
  pivot_longer(everything(), names_to = "parameter", values_to = "estimate") %>% 
  ggplot(., aes(x = estimate, y = parameter)) +
    stat_halfeye() + 
    geom_vline(xintercept = c(ROPE$ROPE_low, ROPE$ROPE_high), linetype = "dashed", color = "skyblue") +
    labs(title = "*Parameter estimates for Bayesian Model*", tag = "Figure 2") +
    mdthemes::md_theme_bw() +
    theme(text=element_text(size=11, family = "Times")) + 
    scale_fill_manual(values = c("gray80", "skyblue"))

p2 <- posterior_table %>% 
  select("b_Intercept", "b_blockpost:conditiondentMbiasing") %>% 
  pivot_longer(everything(), names_to = "parameter", values_to = "estimate") %>% 
  ggplot(., aes(x = estimate, y = parameter, fill = stat(abs(x) < .18))) +
    stat_halfeye() +  
    geom_vline(xintercept = c(ROPE$ROPE_low, ROPE$ROPE_high), linetype = "dashed", color = "skyblue") +
    labs(title = "*Parameter estimates for Bayesian Model*", tag = "Figure 2") +
    mdthemes::md_theme_bw() +
    theme(text=element_text(size=11, family = "Times")) + 
    scale_fill_manual(values = c("gray80", "skyblue"))

# not relevant for our current purposes
# mcmc_hist(posterior_table, pars = c("b_Intercept", "b_blockpost:conditiondentMbiasing"), size = 1.5, alpha = 0.5)
```

p1 + p2

---
```{r rope}
# possible multi-collinearity between b_blockpost.conditiondentMbiasing.vot and b_conditiondentMbiasing.vot (r = 0.75). This might lead to inappropriate results.
ROPE <- bayestestR::rope(bayes_analysis_full,
             range = "default", 
             ci = 0.95, 
             ci_method = "HDI", # or ETI - forgot what the difference is lol
             effects = "all",
             components = "all")
```

# Analysis
# Pre-data
- given out estimates inside ROPE, really only the Intercept and the interaction between the post-block and condition (`blockpost.conditiondentMbiasing`)
  
`r ROPE`

---

# Analysis
## Comparisons

.pull-left{
`r freq_summary`
}
.pull-right{
`r bayes_summary`
}


<!-- LEFT OFF HERE -->

```{r IN-PROGRESS posterior-samples, eval=FALSE, include=FALSE}
#### Model comparison 
waic(bayes_analysis_2 , bayes_analysis_full) 
bayes_factor(bayes_analysis_2, bayes_analysis_full)

# take a closer look at the priors
# prior_summary(bayes_analysis_full)

# table of the posterior estimates
# posterior_table <- as_tibble(bayes_analysis_full)

get_variables(bayes_analysis_full)


cat_plot <- bayes_analysis_full %>% 
  plot(
    combo = c("hist", "trace"), widths = c(1, 1.5),
    theme = theme_bw(base_size = 16)
  )

cat_plot_1 <-  cat_plot[1] # nice looks legit 

# posterior predictive checks

yrep <- posterior_predict(bayes_analysis_full)
y <- as.numeric(test$resp_t)

# i have no idea what these graphs are supposed to mean
test %>% 
  ppc_dens_overlay(test$resp_t, yrep)

color_scheme_set("darkgray")
brms::pp_check(bayes_analysis_2, type = "dens_overlay", nsamples = 500, resp = "resp_t") 

# another attempt at a spaghetti plot ㅠㅠ
test %>%
    add_fitted_samples(bayes_analysis_full, newdata = ., n = 100) %>%
    mutate(estimate = plogis(estimate) ) %>%
    ggplot(aes(x = vot, y = estimate, group = .iteration) ) +
    geom_line(aes(y = estimate), size = 0.5, alpha = 0.1) +
    facet_wrap(~condition, nrow = 2) +
    theme_bw(base_size = 20) + labs(x = "Reminder", y = "Estimate")


# attempting to take samples from the posterior
draws_posterior <- test %>%
  tidybayes::add_fitted_draws(bayes_analysis_full, n = 100, scale = "response") 

draws_posterior <- as.data.frame(draws_posterior)
  
# and trying to plot the values (resp_t) along vot
ggplot(draws_posterior) +
  aes(x = vot, y = .value) +
  geom_line(aes(group = .draw), alpha = .2) +
  geom_point(
    aes(y = resp_t, x = vot),
    color = "#cc0033", size = 4, 
    data = test
  ) +
  theme(
    axis.ticks = element_blank(), 
    axis.text = element_blank(), 
    axis.title = element_blank()
  ) 

# really not going well here lol
test %>% 
  ggplot(., aes(x = vot, y = resp_t)) + 
    geom_abline(data = sample_n(posterior_table, 250), color = "grey80", 
      alpha = 0.2, size = 1, 
      aes(intercept = b_Intercept, slope = `b_blockpost:conditiondentMbiasing`)) + 
    geom_point(pch = 21, fill = "black", size = 5, color = "white") + 
    geom_abline(color = "white", size = 3.5, 
      intercept = fixef(bayes_analysis_full)[1, 1], slope = fixef(bayes_analysis_full)[6, 1]) +
    geom_abline(color = "darkred", size = 1.5, 
      intercept = fixef(bayes_analysis_full)[1, 1], slope = fixef(bayes_analysis_full)[6, 1]) 

# trying to pull out values from the summary output
fixef(bayes_analysis_full)[1, 1]
fixef(bayes_analysis_full)[2, 1]



```









