---
title             : "Right Context Effects and Learning in Speech Perception"
shorttitle        : "Right Context and Learning"

author: 
  - name          : "Joselyn Rodriguez"

bibliography      : ["citations.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
# linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---


```{r setup, include = FALSE}
# APA markdown setup
library("papaja")
r_refs("citations.bib")
```

```{r analysis-preferences}
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, echo = FALSE, fig.width=5, fig.height=3, results = 'hide', message = FALSE, warning = FALSE)

library(tidyverse)
library(readr)
library(lme4)
library(sjPlot)
library(mdthemes)

options(digits=2)

```

```{r old import (ignore)}
# test is the data that Dave cleaned - since I want to include RT here, I can't use this plus it's good practice :(
test <- read_csv("data/batch1-test.csv") %>%
        mutate(block = factor(block, levels=c("pre", "post")),
               resp_t = as.numeric(resp_t))  %>%
        mutate(condition = factor(condition, levels = c("tent-biasing", "dent-biasing")))

exposure <- read_csv("data/batch1-exposure.csv") %>%
            mutate(resp_t = as.numeric(resp_t))
```


```{r cleaning data}

# I'm sorry this is a mess but so was this csv :(
questionnaire <- read_csv("data/batch1.csv", col_types = cols(sender = col_character(), 
                                                         workerId = col_character(), audioequip = col_character(), 
                                                         sex = col_character(), ethnicity = col_character(), 
                                                         race = col_character(), raceother = col_character(), 
                                                         born = col_character(), parent = col_character(), 
                                                         lang = col_character(), comments = col_character(), 
                                                         age = col_number())) %>% 
                select("sender", "workerId", "audioequip":"comments") %>% 
                filter(sender == "Quesionnaire Form")


# block_id, trial, resp are all created variables
data_full <- read_csv("data/batch1.csv", col_types = cols(sender = col_character(), 
                                                         workerId = col_character(), audioequip = col_character(), 
                                                         sex = col_character(), ethnicity = col_character(), 
                                                         race = col_character(), raceother = col_character(), 
                                                         born = col_character(), parent = col_character(), 
                                                         lang = col_character(), comments = col_character(), 
                                                         age = col_number())) %>% 
                select("workerId","condition","stimulus","response","sender","sender_id","block", "duration", "item", "item_block", "time") %>% 
                filter(sender == "Sounds" | sender == "Response") %>% 
                mutate(block_id = substr(sender_id,1,1),
                       resp_t = case_when(substr(response, 1,1) == "t" ~ "TRUE",
                                            substr(response, 1,1) == "d" ~ "FALSE"),
                       vot = substr(stimulus, 11, 12))

# this is the data for just the pre- and post-tests 
data_test <- data_full %>% 
                select("workerId","condition","stimulus","response","sender","sender_id","duration", "block_id") %>% 
                mutate(block = case_when(block_id=="6"~ "pre",
                                         block_id=="10"~ "post")) %>% 
                filter(block == "pre" | block == "post") %>% 
                filter(sender == "Sounds")

data_exposure <- data_full %>% 
                  select("workerId","condition","response","sender","block_id","duration", "item","time") %>% 
                  filter(block_id == "8") %>% 
                  filter(sender == "Response") %>% 
                  mutate(bias = case_when(str_detect(item, "tent")~ "tent",
                                          str_detect(item, "dent")~ "dent"))

# write output to csvs

# write_csv(data_full, "data/data_full.csv")
# write_csv(data_test, "data/data_test.csv")
# write_csv(data_exposure, "data/data_exposure.csv")
# write_csv(questionnaire, "data/questionnaire.csv")
```

# Introduction

<!--

The important questions here are surrounding ambiguity. The problem is that to have a discussion about ambiguity, we're also going to have to talk about prediction and uncertainty. For the garden path sentence, you can't really say it's ambiguous (can you?) because it's not actually ambiguous until you reach a certain point in the sentence and your parse fails. It's not ambiguous in the same way that a word could be semantically or acoustically ambiguous between multiple different words (and you're aware of that ambiguity). This is all to say that I think the question needs to be framed slightly differently. 

A better way to think about this here is about how long ambiguity is maintained and how ambiguous a word needs to be in order for ambiguity to be maintained in the first place (this was the whole deal with that Bicknell et al paper)

-->

Ambiguity is ever present aspect of speech comprehension. The speech comprehension system then must be able to handle uncertainty in processing at multiple levels including phonetic, lexical, syntactic, semantic, and pragmatic. 

A classic example of syntactic ambiguity are  "garden path sentences" which display uncertainty that arises due to a error in syntactic parsing early in the sentence that leads to a breakdown in comprehension - i.e., the "garden path". This can be seen in a sentence like the following: "the horse ran past the barn *fell*". In order to ascertain the correct meaning of the sentence, the structure must be disambiguated at a specific point in the sentence at which the listener is able to re-parse the sentence correctly. On the other than, lexical ambiguity can be illustrated through homophony, in which one word may relate to multiple meanings depending on the context. 

In the acoustic-phonetic domain, ambiguity that is present in the signal can be due to several factors including variation in pronunciation attributed to physical factors (vocal tract length, mouth shape) as well as socio-economic factors (dialect, gender, economic status). The amount of variation present in the signal often leads to scenarios in which the identity of a word or segment is ambiguous without further information. An example of this is best illustrated across spectral center of gravity in fricatives (like /s/ and /sh/), where it's possible that a speaker's production of /s/ may overlap _entirely_ with a different speaker's production of /sh/, making identification of the segment ambiguous between the two without further contextual information (for example, one person's production of "ship" would overlap completely with a different talker's production of "sip"). 

Because such uncertainty is a persistent issue in speech comprehension, several theories have been proposed to account for it. Many of these theories have assumed that when ambiguous information is encountered, it is processed immediately and passed to higher levels of representation and all uncertainty regarding category membership is discarded [@christiansen_now-or-never_2016]. While such "chunk-and-pass" models of speech perception have received influence within the field, evidence from studies in speech perception have shown that ambiguous information later in the sentence is still capable of influencing previous interpretation, suggesting that gradient information in the speech signal is not processed immediately and is at least available for backward influence in the local right-context. 

For example, while previous accounts of speech recognition have assumed that identification of a word occurs within 200ms of word onset [@marslen-wilson_access_1989], research from @Connineetal1991 and @szostak_prolonged_2013 suggests that words are not processed immediately upon presentation, but rather that this ambiguous representation is _maintained_ in memory until disambiguating information is encountered in the signal. 

Surprisingly, the results of @Connineetal1991 suggested that this information was maintained for a considerable amount of time - up to seven syllables *following* exposure to the ambiguous target, in the right context of the target word. Thus, in a sentence in which an ambiguous target ('?ent') is encountered, this ambiguity can be maintained for up to seven syllables as the sentence progresses until a disambiguating cue is reached ('mountain') such as in the example: "Because the _?ent_ was so hard to find on the _mountain_, we had to point it out." In this example sentence, the segment ambiguous between a /d/ or /t/ is unable to be resolved at the word-level because either of these realizations would be acceptable within that context because "tent" and "dent" are both real words of English. 

The listener is unable to determine whether the correct reading of the ambiguous word is "tent" or "dent" until they encounter the word "mountain" which allows the listener to realize the talker is discussing an outdoor scenario in which a discussion of "tents" is more likely than "dents". While these previous studies have shown that this ambiguity can be maintained until disambiguating information is acquired rather than immediately determined from the available acoustic input, it is still unknown whether this effect is strong enough to facilitate learning. Previous studies of segmental ambiguity have found that lexical disambiguation of an ambiguous target segment induces learning (i.e., recalibration) of that target segment. For example, take into consideration /d/ and /t/ in the following words: croco[d]ile" and "cafe[t]eria". 

Since these segments are unambiguously /t/ or /d/ within the word (since the word "crocotile" doens't exist), the ambiguous segment within this lexical context serves to shift the boundary of the assumed category (/d/ for "crocodile") with respect to the ambiguous target. However, whether such recalibration effects will occur in a situation such as lexical ambiguity where the disambiguating semantic context occurs significantly later in the sentence is an open question.

<!--
  You know, now that I'm thinking about this more - I don't think it's possible to really make this kind of claim. 
-->

It is possible that when encountering an ambiguous word that could have multiple lexical realizations, both of those words are activated in the lexicon and the listeners is maintaining gradient activation of these words after which one is chosen as the sentence proceeds. In this case, there would be no expectation of recalibration since the level at which the ambiguity is maintained is that of the lexical entry. However, if it is true that the ambiguous information that is being maintained is at a lower level such as the segmental level, then it's possible that disambiguation of the word would also lead to recalibration of that ambiguous phonetic segment. 

This is supported by recent results from @burchill_maintaining_2018 which suggest that it is possible that information provided after ambiguous information can guide learning of speech encountered previously in the signal. In this study, learning of a foreign accent was facilitated by subtitles provided up to six seconds after subjects heard the accented speech, suggesting that not only is gradient information maintained, but that phonetic adaptation given new information later in the signal is possible. 

<!--
  added in some information about response times, but honestly i dont think this reponse time is nearly accurate enough to be making any claims at all lol
-->

Therefore, the current project addresses the question of whether learning of segmental information can be facilitated through semantic information present later in a sentence in the right context using a perceptual learning paradigm. The hypothesis is that if segmental information is being maintained during processing, then the disambiguation in the right context may be able to facilitate recalibration of a target /t/-like segment depending on the semantic biasing context. If this is indeed the case, we would expect to see an increase in the proportion of /t/-responses in the tent-biasing condition and decrease in /t/-responses in the dent-biasing condition. Additionally, response times for the categorization functions are expected to be larger for more ambiguous stimuli. Thus, the categorization should be slower towards the center of the continuum for the categorization tasks as well as for the more ambiguous items present in the exposure phase. This would suggest that the participants are indeed perceiving the stimuli as ambiguous. 

This paradigm consists of a pre-exposure block in which participants respond to stimuli from a tent-dent continuum to get a baseline of their prior categorization followed by an exposure phase in which subjects hear 40 sentences containing a target word "?ent" within a sentence biasing participants towards "tent" or "dent" interpretations. 


# Methods

This study followed standard procedures for conducting perceptual learning experiments online and was approved by the Institutional Review Board at Rutgers University. 


### Participants

```{r participant data}
num_part = nrow(questionnaire)
avg_age = mean(questionnaire$age)
med_age = median(questionnaire$age)
sd_age = sd(questionnaire$age)
num_fem = count(questionnaire %>% filter(sex == "Female"))
num_male = count(questionnaire %>% filter(sex == "Male"))
hisp = count(questionnaire %>% filter(ethnicity == "Hisp"))
eng = count(questionnaire %>% filter(parent == "yes"))
audio = table(questionnaire$audioequip) 
```

60 participants total (23 Females; 1 unknown) took part in the experiment. The average age was 40.63 years (*M*: `r avg_age`; *Mdn* = `r med_age`; *SD* = `r sd_age`). 57 participants indicated that English was the language spoken at home (other = 2, NA = 1). Only one participant indicated what other language was spoken other than English (Russian). These participants were included as their language background isn't expected to have a major effect in this study since we are looking at a within-subject effect and even if they were utilizing categorization function from a different language, we would still expect to see a shift in their categorization function following exposure. 

Participants were recruited through Amazon's Mechanical Turk and compensated for their time at a rate of $5/30 minutes. The experiment was created using Lab.js and lasted around 25 minutes but participants were given up to an hour to complete it [@henninger_felix_2020_3953072]. Since the experiment was conducted online and required listening to auditory stimuli, prior to beginning the participants were told to use headphones and completed a quick screening utilizing phase cancellation such that detection of loudness of spatially distributed tones was only possible if they were wearing headphones. Participants were thus only able to proceed to the experiment if they achieved above 66% accuracy in identifying the softest auditory tone. Participants were only able to proceed with the experiment if they passed the headphone check. However, participants were able to then put on headphones and retake the headphone check in order to proceed with the experiment. Therefore, all data presented here are from participants who passed this check. As this experiment is performed online, additional information about the quality of their headphones was collected from participants voluntary in the questionnaire -- the majority of the participants who responded to the questionnaire used in-ear headphones costing less than \$30 (N = 27) or \$100 (N = 13). Less than half of the participants used over-the-ear headphones (N = 17). While the majority of participants were using potentially lower-quality headphones, this is not expected to impact the results.

The experiment consisted of three tasks: two categorization tasks on a tent-dent continuum and an exposure phase which exposed participants to a specific biasing context. Participants were randomly assigned to only one of two conditions: tent-biasing and dent-biasing. Both conditions received the same pre and post tests, but received different biasing contexts for ambiguous stimuli in the exposure phase. After the participants completed the experiment, they were asked to take part in a voluntary questionnaire.

### Materials 

The stimuli for this experiment consisted of a synthesized tent-dent continuum with VOT (voice onset time) for the stop consonants ranging from 10 to 85 ms in 5ms intervals for a total of 16 tokens. The exposure sentences consisted of sentences produced by a single female talker. These sentences were new recordings of the same sentences used in a previous study examining right context effects [@Connineetal1991]. While it has indeed been shown that ambiguity is maintained in sentences up to seven syllables after target exposure, for the purposes of the current study, only short lag sentences in which the disambiguating information appeared approximately three syllables following the target word were used in order to maximize possible learning effects.

Exposure sentences consisted of 20 unique sentences in which a target word appeared at the beginning of the sentence followed by some disambiguating contextual information within approximately three syllables following this target word. The following is an example sentence:

(1) Since the **tent** at the **camp** was removed, we were able to leave.

Half of the sentences contained an ambiguous segment at 50ms while the other half were canonical given the contextual information such that the biasing context matched the VOT of the target segment. For example, in a tent-biasing condition, a normal /d/-biasing context was matched with an acoustically canonical production of /d/ at 10ms while the /t/-biasing sentences were matched with the ambiguous /t/ production at 50ms. This ensured that participants received both ends of the possible range of VOT for a given ambiguous segment. Thus, participants were exposed the the "full range" of the talker in a given condition. To create the exposure sentences, ambiguous segments were synthesized from natural productions by a female American English talker using Praat [@Boersma2009] and spliced onto "-ent" endings that were cut back into the full sentence, creating a naturalistic full production of each sentence. 

### Pre and Post Continuum tasks

The first and final task that the participants completed was a categorization of a tent-dent continuum. As discussed above, the stimuli for this task consisted of a continuum with VOT ranging from 10ms (/d/-like) to 85ms (/t/-like), synthesized from tokens produced by a single female talker. These 16 items were repeated in 8 blocks for a total of 128 tokens and lasted approximately 7 minutes. During this task, participants heard a tent-dent token while seeing "tent" or "dent" displayed on the left and right hand sides of their computer screen and were prompted to respond using the "F" and "J" keys for "tent" or "dent" respectively followed by a fixation cross and ISI of 500ms. Response times were measured as the time it took participants to respond after the stimulus was displayed on the screen. After completion of the pre-continuum task, participants were given the option of taking a short break and then began the exposure phase. The participants completed an identical continuum task again following completion of the exposure phase. Participants were not able to respond before hearing the entirety of the stimulus.

### Exposure Phase

In the exposure phase, participants in both conditions first saw a fixation cross for the duration of the sentence as they heard it and were then prompted to respond whether they heard "tent" or "dent" in the sentence by using the 'f' or 'j' key respectively. Participants were not allowed to respond until after the sentence had completely finished playing. Response times for the exposure phase were recorded as the time it took participants to respond after the Requiring a response served two purposes in this task. First, it was a way of ensuring participants' attention throughout the task and second, it was a way of testing whether participants were indeed perceiving the items as expected given previous research regarding right context effects. As such, we would expect that the responses for this section would follow previous patterns showing response influenced by their biasing context such that the responses are semantically consistent with the right context. The exposure phase consisted of 20 unique sentences with 3 repetitions for a total of 80 tokens and lasted approximately 11 minutes. 



# Results


The results of the continuum tasks and response were analyzed separately. For the continuum task, the data were analyzed using a generalized linear mixed effects model (logit link) with fixed predictors of random intercepts for
subject, item, and random slopes for subjects

<!-- I think the model should actually be around something like this 

test_model <- glmer(resp_t ~ block * condition + vot +
                              (1| workerId),
                              data = test, family = "binomial")
-->                              
                              
                              

### Pre- and Post-Continuum tasks


```{r continuum task means}

# resp_t is a binomial variable - yes/no

# check the Buxo - Lugo & Kurumada (preprint) as an example
 
# subset the data into pre and post tests
pre_test <- test %>% 
  filter(block == "pre")

post_test <- test %>% 
  filter(block == "post")

# mean proportion /t/ responses in pre & post
mean_pre = mean(pre_test$resp_t)
mean_post = mean(post_test$resp_t)

# mean /t/ responses in pre for /t/ and /d/ biasing conditions - should be the same 
mean_pre_t = mean(pre_test[pre_test$condition == "tent-biasing",]$resp_t) 
mean_pre_d = mean(pre_test[pre_test$condition == "dent-biasing",]$resp_t)

# mean /t/ responses in pre for /t/ and /d/ biasing conditions - should be different; this is what the logistic regression is interested in... 
mean_post_t = mean(post_test[post_test$condition == "tent-biasing",]$resp_t)
mean_post_d = mean(post_test[post_test$condition == "dent-biasing",]$resp_t)
```

The mean proportion of responses in the pre-continuum trial indicated a slight preference for /t/-responses across the continuum (*M* = `r mean_pre`) with minimal difference between the two conditions in the pre-task as would be expected prior to the exposure phase (/t/-biasing: *M* = `r mean_pre_t` ; /d/-biasing  *M* = `r mean_pre_d`). Preliminary analysis of the mean proportion of /t/ responses for the post-task (*M* = `r mean_post`) are similar to the pre-task as would be expected collapsed over both conditions. 


```{r continuum plots}

cont_tasks <- ggplot(data = test,
       aes(x=vot, y=resp_t, color = block, group = workerId)) +
  # uncomment to see the actual data points instead of just the mean
  # geom_point(position=position_jitter(h = 0.1), alpha=0.1) +
  geom_line(stat="summary", fun = mean) +
  geom_vline(xintercept = 50, linetype = "dashed", aes( color = "red")) +
  # the line below shows where it seems to actually be ambiguous 
  # geom_vline(xintercept = 40, linetype = "dashed", color = "blue", alpha = 0.5) +
  facet_wrap( . ~ condition) +
  ylab("Proportion of /t/ response") + xlab("VOT (ms)") +
  labs(title = "*Pre- and Post Continuum 'Tent' Responses*", tag = "Figure 1") +
  mdthemes::md_theme_bw() +
  theme(text=element_text(size=11, family = "Times"))
cont_tasks

```

However, the mean proportion of /t/ responses for the /t/-biasing condition in the post-task indicate a slight difference between their original proportion of responses in the pre-task (*M* = `r mean_post_t`). While the proportion of /t/ responses in the /d/-biasing condition does seem to be trending in the expected direction of fewer /t/ responses (*M* = `r mean_post_d`), the difference is small. These results are visualized in Fig. 1 above for each step of the VOT continuum. The dashed-red line marks the predicted highest point of ambiguity in the "tent" to "dent" continuum given prior literature on perceptual learning. 

```{r glmer full test data, echo=FALSE, message=TRUE}

# generalized linear mixed effects modeling

# base model | AIC: 15951
base <- glm(resp_t ~ 1, data = test, family = "binomial")
# summary(base)

summary(base)
 
# AIC: 15917 | BIC: 15932
base_random <- glmer(resp_t ~ 1 + 
                        (1 | workerId),
                        data = test, family = "binomial")
# summary(base_random)
 
# AIC: 6106 | BIC : 6143
full_test_model_1 <- glmer(resp_t ~ condition + block + vot +
                               (1| workerId),  
                               data = test, family = "binomial")
# summary(full_test_model_1)

# FINAL MODEL (marginally better fit): AIC: 6098 | BIC: 6142 
test_model <- glmer(resp_t ~ block * condition + vot +
                              (1| workerId),
                              data = test, family = "binomial")
summary(test_model)

# model comparison, full_test_model_2 is marginally better
tab_model(full_test_model_1, test_model)
anova(full_test_model_1, test_model)


miscmodel <- glmer(resp_t ~ block * condition +
                              (1 | workerId) + 
                              (1 | condition) +
                              (1 | block),
                              data = test, family = "binomial")
summary(miscmodel)
```

In order to further examine these effects, these results were analyzed using a generalized linear mixed effects model with the lme4 package in R [@lme4] with fixed effects of condition, block, and VOT and random effect of subject. The GLMM revealed a significant main effect of block, such that the proportion of /t/-responses was smaller in post block than in the pre-block ($\hat{\beta}$ = -0.464, *SE* = 0.095, *z* = -4.85, *p* < 0.001) and VOT ($\hat{\beta}$ = 0.159, *SE* = 0.003, *z* = 52.59, *p* < 0.001) no main effect of condition ($\hat{\beta}$ = -0.039, *SE* = 0.203, *z* = -0.20, *p* = 0.845). 

There was also a marginally significant interaction between condition and block suggesting that the proportion of /t/-responses differed based on condition across the blocks such that those in the tent-biasing condition made significantly more /t/-responses than the dent-biasing condition in the post-block ($\hat{\beta}$ = 0.43110, *SE* = 0.13241, *z* = 3.26, *p* = 0.001). 


### Exposure Phase 

The purpose of this phase was to expose participants to the new distribution of VOT in order to facilitate recalibration of phonemic boundaries. In order to ensure participants engagement with the task and to replicate previous findings in studies of right context effects, participants were prompted to respond whether they heard "tent" or "dent" on each trial after hearing a full sentence biasing participants towards a "tent" or "dent" interpretation.

```{r exposure phase means}
# accuracy is a binomial variable - yes/no
exposure <- exposure %>% 
  mutate(correct = as.numeric(response == bias))

# mean proportion correct responses
mean_correct = mean(exposure$correct)

# mean correct responses by condition
mean_correct_t = mean(exposure[exposure$condition == "tent-biasing",]$correct)
mean_correct_d = mean(exposure[exposure$condition == "dent-biasing",]$correct)
```

As can be seen from Fig. 2 below, the responses for the canonical matchings -- situations in which the VOT of the target word matched the biasing context (85ms in the dent-biasing and 10ms in the tent-biasing), the performance was close to ceiling. In these situations, the stimulus was unambiguous and matched the context such that "tent" in the dent-biasing condition was matched with an unambiguous /t/-biasing context while the ambiguous token at 50ms was matched with the /d/-biasing contexts. 

For example, take the following sentence: "When the [t]ent in the forest was well camouflaged, we began our hike" - in this sentence, the dent-biasing condition participants would hear an *unambiguously* /t/-like token with a VOT of 85ms. The ambiguous 50ms token would then appear in /d/-biasing contexts such as the following: "When the ?ent in the fender was well camouflaged, we sold the car." The opposite situation would be true of the tent-biasing sentences in which subjects would hear an unambiguously /d/-like token with a VOT of 10ms matched with a corresponding /d/-biasing sentence while the ambiguous token with a VOT of 50ms would be matched with the /t/-biasing sentence. 

Therefore, the matching of the ambiguous segments with a specific semantic biasing context would cause participants to reinterpret the ambiguous token as a new "standard" token for the speaker. Critically, unlike previous experiments examining right context effects, in this experiment, we only exposed participants to scenarios in which *ambiguous* tokens were matched with either biasing context and *canonical* productions of tent and dent were matched with with their respective biasing context such that participants never heard a unambiguous "tent" (/t/ with 85ms VOT) within a conflicting dent-biasing context. As perceptual learning effects in the literature are often small, the purpose of this decision was to maximize any effect that may appear in the post-continuum task given the exposure phase.

```{r exposure phase accuracy}
accuracy_plot <- ggplot(data = exposure, aes(x=vot, y=correct, fill = bias)) +
  # uncomment for the actual data points
  # geom_point(position=position_jitter(h = 0.1), alpha=0.1) +
  facet_wrap(.~condition) +
  xlab("VOT (ms)") + ylab("proportion correct") +
  geom_bar(stat = "summary", fun = mean, width=15) + 
  scale_x_continuous(breaks=c(10,50,85), limits=c(0, 95)) +
  labs(title = "*Accuracy by VOT*", tag = "Figure 2") +
  mdthemes::md_theme_bw() +
  theme(text=element_text(size=11, family = "Times"))
accuracy_plot 
```

While the accuracy of responses for the canonical pairings were at ceiling as expected, visual inspection of the proportion of correct responses given the biasing context differed between both the dent-biasing and tent-biasing conditions. A priori, it would be expected that the responses for the ambiguous tokens should be around the same accuracy for both conditions since the token is ambiguous and thus should be reinterpreted given any semantic content in the right context. However, this is not the case. The average proportion correct responses in the dent-biasing condition was 83% compared to 93% in the tent-biasing condition indicating more accurate responses in the tent-biasing condition than the dent-biasing condition overall ($\hat{\beta}$= 3.897, *SE* = 0.630, *z* = 6.18, *p* < 0.001). 

```{r exposure phase accuracy glmm}

############
# accuracy #
############

# another glm to explore relationship of accuracy between conditions
exp_model_acc <- glmer(correct ~ bias * condition + (1|workerId),
                        data = exposure, 
                        family = "binomial")
summary(exp_model_acc)

```
 
However, as we saw in the pre- and post-continuum tasks as well, it's likely that this difference in accuracy in the ambiguous region is due to a difference in participants' prior categorization of /t/ and /d/. As can be seen in Fig. 3, participants' boundaries between /t/ and /d/ seem to be lower than assumed and thus generally more biased to give more /t/ responses for the 50ms token even in the dent-biasing contexts. 


```{r exposure proportion response}

exp_resp_t <- ggplot(data = exposure,
       aes(x=vot, y=resp_t)) +
  # comment out to get rid of the actual data points instead of just the mean
  geom_point(position=position_jitter(h = 0.05), alpha=0.5, aes(color = bias)) +
  geom_line(stat="summary", fun = mean) +
  geom_vline(xintercept = 50, linetype = "dashed", color = "red") +
  scale_x_continuous(breaks=c(10,50,85), limits=c(0, 95)) +
  facet_grid(.~condition) +
  ylab("Proportion of /t/ response") + xlab("VOT (ms)") +
  labs(title = "*Proportion of 'Tent' Response by VOT*", tag = "Figure 3") +
  mdthemes::md_theme_bw() +
  theme(text=element_text(size=11, family = "Times"))
exp_resp_t

```

```{r exposure phase proportion glmm}

##################
# proportion /t/ #
##################

# a explore relationship between proportion /t/ in both conditions 
exp_model_prop <- glmer(resp_t ~ bias * condition + (1|workerId),
                          data = exposure, 
                          family = "binomial")
summary(exp_model_prop)

```

An analysis of the *proportion* /t/ responses for the exposure task, we see that there is also significantly more /t/ responses for the /t/-biasing sentences within tent-biasing condition as expected ($\hat{\beta}$ = 2.471, *SE* = 0.441, *z* = 5.61, *p* < 0.0001). However, there are fewer overall /t/ responses in the tent-biasing condition ( $\hat{\beta}$ =-3.854, *SE* = 0.614, *z* = -6.27, *p* < 0.0001). Given that both conditions have equal number of tent- and dent-biasing sentences, the total number of /t/ responses should be the same. However, this is likely the case because in the dent-biasing condition, since the ambiguous region was perceived as /t/, the responses in this condition were either unambiguously /t/ for 85ms token in the tent-biasing sentences and 50ms in the dent-biasing sentences such that it resulted in overall higher /t/ responses. However, since participants in the tent-biasing condition never received the unambiguous 85ms /t/ token but instead received the unambiguously /d/ (10ms) token, they had fewer overall /t/ responses.
 
# Discussion

<!--
You're going to have to double check the first paragraph below. I moved some of what was in the results section there because it seemed to fit better as part of the discussion. However, I haven't looked over it to actually make everything flow correctly yet
-->

Analysis of the results suggest that exposure to a shifted distribution of /t/-/d/ stimuli within semantic right-contexts biasing participants into either a "tent" or "dent" interpretation did lead to a modest learning in the participants. In previous studies, participants have usually displayed a categorization function with a boundary between these two segments at around 50ms. Preliminary analysis of the categorization data, however, suggests that participants displayed a boundary more closely to 40ms rather than 50ms. Note, however, that the exposure phase was already set with the prior assumption of 50ms so this is the token that was used as the ambiguous token in the exposure phases as well. With this in mind, from visual inspection, although the token at 50ms was already biased towards /t/ responses, there still seemed to modest learning effect as can be seen through the separation of categorization boundaries for the dent-biasing sentences in the post-test. 

This suggests that not only do right context effects influence interpretation and maintenance of ambiguous lexical items ("tent" or "dent"), but that they are maintained a finer-grained level of representation such as phonetic content which allows for perceptual learning to take place. Additionally, the fact that there was only a small effect of condition in the post block for the tent-biasing sentences suggests that the exposure stimuli, as expected, were not ambiguous enough to induce strong recalibration of /t/ categories in subjects as the proportion of /t/ responses only marginally increased for tent-biasing sentences. Thus, given the results as seen in Figure 1, it's possible that the effect was driven by a decrease in proportion of /t/ responses for the /d/-biased group rather than an in increase in /t/ responses for the /t/-biased group. 

An additional finding of note is that of the exposure phase. The purpose of this phase was a replication of previous findings that the semantic content of the right context affected subjects' lexical response (tent or dent). However, the findings here were much stronger than those of previous findings as participants were incredibly high overall in their accuracy of identifying the "correct" word given the biasing context of the sentence. This is likely due to our stimuli such that the subjects only ever saw ambiguous stimuli in biasing scenarios that were acoustically plausible. For example, they never saw a 10ms (/d/-like) sound in a tent-biasing context as was the situation in previous studies. In order see whether this is because of this design or because of some other unrelated experimental factor, future research will have to recreate these effects with stimuli that follow the previous research as in @Connineetal1991 more closely.

While the overall accuracy was high, there was the same issue as seen in the pre- and post-tests of subjects' general bias towards /t/ responses, likely due to a difference between our inferred ambiguous token at 50ms actually reliably categorized as /t/ prior to beginning the study. Since this token was not actually ambiguous, the participants had a strong bias towards /t/ responses throughout the entire experiment, leading to the lower accuracy in the /d/-biasing sentences in the dent-biasing condition as these tokens that were presumed to be ambiguous were in fact continually perceived as /t/ instead of /d/ as predicted. 

However, it is worth mentioning that while the accuracy for these tokens were *lower* than those in the tent-biasing condition, the accuracy was still relatively high, meaning that participants did understand the purpose of the task and were generally behaving as expected which makes sense as there was still was an effect of learning as seen in the post-test. This suggests that while participants did have a prior bias towards /t/ responses given their categorization functions, their categorization of their /t/ categories were still shifted, however the effect was small. Therefore, in order to better examine this effect, future research will have to address this by either re-setting the ambiguous token as 40ms or utilizing a task that would allow for the determination of each participants' individual categorization functions for use in the exposure phase. 

Additionally, in the experiment, participants were exposed to the entire acoustic continuum in the pre-continuum task. It's possible that being exposed to the entire continuum, especially over multiple blocks, influenced participants' expectation of the talker's VOT space. In order to account for such an effect, future research will have to either remove a pre-test, or ensure that the tokens that the subject is exposed to in the pre-test correspond to the those in the condition they have been assigned.

Therefore future research must address these concerns in order to further examine how it is that participants make use of their surrounding context to guide interpretation and adaptation to the speech they are exposed to. Addressing these issues with allow for better understanding of ambiguity maintenance and resolution in speech perception as well as the flexibility of the perceptual system.

# Conclusion

This study was concerned with addressing learning with respect to right context effects. While previous results in the literature have found strong evidence support the original findings of @Connineetal1991 in which the semantic content in the right context affected identification of a lexical target, to date, no studies have examined what the level of ambiguity that is being maintained is and whether these effects are able induce recalibration-like effects. Prior findings of recalibration effects have mainly utilized lexical designs in which an ambiguous phonetic target is embedded in a lexical item which serves as the disambiguating context. The current project utilized the semantic right context as the disambiguating context for an ambiguous segment within an word ambiguous between 'tent' and 'dent'. Thus, these results support the hypothesis that right context effects seen in studies of lexical ambiguity not only guide lexical target access, but also lead to recalibration of phonemic categories when the segmental information is ambiguous. These results may also suggest that the level of representation at which ambiguity is maintained is lower than even a lexical level such that perhaps the lower-level phonetic representations are maintained long after the word has been been heard.



# References 

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
<div id="refs" custom-style="Bibliography"></div>
\endgroup
